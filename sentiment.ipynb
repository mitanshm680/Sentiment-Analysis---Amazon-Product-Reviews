{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing unnecessary fields\n",
    "### Description\n",
    "This Python script reads a large JSON Lines (JSONL) file line by line, processes each entry to remove the specified fields, and writes the cleaned data into a new JSONL file. The script is optimized for handling large datasets by processing entries incrementally to avoid memory overload, making it suitable for datasets containing millions of records.\n",
    "\n",
    "### Features\n",
    "Field Removal: Removes non-essential fields (images, videos, details, and features) from each entry.\n",
    "Memory Efficiency: Processes each line independently without loading the entire file into memory.\n",
    "Scalability: Capable of handling datasets with millions of entries due to its line-by-line processing approach.\n",
    "Preserves Original Structure: Maintains the integrity of the remaining data fields, ensuring the dataset is ready for subsequent analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data written to cleaned_metadata.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Input and output file paths\n",
    "input_file = \"updated_metadata.jsonl\"\n",
    "output_file = \"cleaned_metadata.jsonl\"\n",
    "\n",
    "# Fields to remove\n",
    "fields_to_remove = [\"images\", \"videos\", \"details\", \"features\", \"bought_together\", \"description\"]\n",
    "\n",
    "# Process the file\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for line in infile:\n",
    "        entry = json.loads(line.strip())  # Load the JSON object\n",
    "        # Remove the specified fields\n",
    "        for field in fields_to_remove:\n",
    "            entry.pop(field, None)\n",
    "        # Write the cleaned entry to the output file\n",
    "        outfile.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "print(f\"Cleaned data written to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cleaning reviews\n",
    "Objective:\n",
    "The purpose of this step is to preprocess the cleaned_metadata.jsonl file by removing unnecessary subfields from the reviews field. This process ensures that only the relevant information for sentiment analysis is retained in the reviews data, making it cleaner and more focused for downstream processing.\n",
    "\n",
    "Description:\n",
    "In this step, we focus on cleaning the reviews field within each entry of the cleaned_metadata.jsonl file. Specifically, we remove the following unwanted subfields from each review:\n",
    "\n",
    "parent_asin\n",
    "user_id\n",
    "asin\n",
    "helpful_vote\n",
    "These fields are irrelevant for sentiment analysis, as they do not contribute to evaluating the tone or opinion expressed in the review. By removing these fields, we reduce noise in the dataset, streamline the structure, and make it easier to analyze the sentiment of the reviews based on the remaining relevant fields, such as rating, title, text, and timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews cleaned and file cleaned_metadata.jsonl updated.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Input and output file paths (same file for input and output)\n",
    "file_path = \"cleaned_metadata.jsonl\"\n",
    "\n",
    "# Fields to remove within the reviews\n",
    "review_fields_to_remove = [\"parent_asin\", \"user_id\", \"asin\", \"helpful_vote\", \"images\"]\n",
    "\n",
    "# Process the file\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as infile:\n",
    "    lines = infile.readlines()  # Read all lines into memory\n",
    "\n",
    "# Modify the data\n",
    "modified_lines = []\n",
    "for line in lines:\n",
    "    entry = json.loads(line.strip())  # Load the JSON object\n",
    "    \n",
    "    # Clean the reviews field\n",
    "    if \"reviews\" in entry and isinstance(entry[\"reviews\"], list):\n",
    "        cleaned_reviews = []\n",
    "        for review in entry[\"reviews\"]:\n",
    "            # Remove specified fields in each review\n",
    "            cleaned_review = {k: v for k, v in review.items() if k not in review_fields_to_remove}\n",
    "            cleaned_reviews.append(cleaned_review)\n",
    "        entry[\"reviews\"] = cleaned_reviews\n",
    "\n",
    "    # Prepare the modified entry for output\n",
    "    modified_lines.append(json.dumps(entry))\n",
    "\n",
    "# Overwrite the file with the modified data\n",
    "with open(file_path, \"w\", encoding=\"utf-8\") as outfile:\n",
    "    for modified_line in modified_lines:\n",
    "        outfile.write(modified_line + \"\\n\")\n",
    "\n",
    "print(f\"Reviews cleaned and file {file_path} updated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further cleaning data and feature engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert dates to suitable format and remove html tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mitan\\AppData\\Local\\Temp\\ipykernel_17096\\3263700859.py:15: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  return datetime.utcfromtimestamp(timestamp / 1000).strftime('%Y-%m-%d %H:%M:%S')\n",
      "C:\\Users\\mitan\\AppData\\Local\\Temp\\ipykernel_17096\\3263700859.py:19: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  return BeautifulSoup(text, \"html.parser\").get_text()\n",
      "C:\\Users\\mitan\\AppData\\Local\\Temp\\ipykernel_17096\\3263700859.py:19: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  return BeautifulSoup(text, \"html.parser\").get_text()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp converted and HTML tags removed successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Load your cleaned data\n",
    "import json\n",
    "\n",
    "# Read the cleaned metadata (ensure it's in the proper JSON format for manipulation)\n",
    "with open(\"cleaned_metadata.jsonl\", \"r\") as file:\n",
    "    cleaned_data = [json.loads(line) for line in file]\n",
    "\n",
    "# Function to convert Unix timestamp to a readable date\n",
    "def convert_timestamp(timestamp):\n",
    "    # Convert milliseconds to seconds for datetime conversion\n",
    "    return datetime.utcfromtimestamp(timestamp / 1000).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Function to remove HTML tags from the review text\n",
    "def remove_html_tags(text):\n",
    "    return BeautifulSoup(text, \"html.parser\").get_text()\n",
    "\n",
    "# Apply the transformations to the data\n",
    "for entry in cleaned_data:\n",
    "    # Convert timestamp for each review\n",
    "    for review in entry.get('reviews', []):\n",
    "        review['timestamp'] = convert_timestamp(review['timestamp'])\n",
    "        # Remove HTML tags in the review text\n",
    "        review['text'] = remove_html_tags(review['text'])\n",
    "\n",
    "# Save the updated data back to cleaned_metadata.jsonl\n",
    "with open(\"cleaned_metadata.jsonl\", \"w\") as file:\n",
    "    for entry in cleaned_data:\n",
    "        file.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "print(\"Timestamp converted and HTML tags removed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding new fields such as review_count and price range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review Count and Price Range features added successfully, handling null and non-numeric prices.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Function to add Review Count feature\n",
    "def add_review_count(data):\n",
    "    for entry in data:\n",
    "        entry['review_count'] = len(entry.get('reviews', []))  # Count reviews for each product\n",
    "    return data\n",
    "\n",
    "# Function to add Price Range feature, handling null prices and converting to numeric\n",
    "def add_price_range(data):\n",
    "    for entry in data:\n",
    "        price = entry.get('price', None)  # Get the price, default to None if not present\n",
    "        \n",
    "        # If the price is None or empty, set to 'unknown'\n",
    "        if price is None or price == '':\n",
    "            entry['price_range'] = 'unknown'  # Set as 'unknown' if price is missing or empty\n",
    "        else:\n",
    "            try:\n",
    "                # Convert price to float to ensure proper comparison\n",
    "                price = float(price)\n",
    "                if price < 10:\n",
    "                    entry['price_range'] = 'low'\n",
    "                elif 10 <= price < 30:\n",
    "                    entry['price_range'] = 'medium'\n",
    "                else:\n",
    "                    entry['price_range'] = 'high'\n",
    "            except ValueError:\n",
    "                # If conversion fails (e.g., if price is non-numeric), set it as 'unknown'\n",
    "                entry['price_range'] = 'unknown'\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Load the cleaned data from the cleaned_metadata.jsonl file\n",
    "with open(\"cleaned_metadata.jsonl\", \"r\") as file:\n",
    "    cleaned_data = [json.loads(line) for line in file]\n",
    "\n",
    "# Apply Review Count and Price Range feature engineering\n",
    "cleaned_data = add_review_count(cleaned_data)\n",
    "cleaned_data = add_price_range(cleaned_data)\n",
    "\n",
    "# Save the updated data with the new features to the same file\n",
    "with open(\"cleaned_metadata.jsonl\", \"w\") as file:\n",
    "    for entry in cleaned_data:\n",
    "        file.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "print(\"Review Count and Price Range features added successfully, handling null and non-numeric prices.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
